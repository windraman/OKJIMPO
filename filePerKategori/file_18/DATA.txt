we give some notations of these probabilities below. ( )P t : the probability that a document x  contains term t ; ( )iP c : the probability that a document x  does not belong to category ic ; ( , )iP t c : the joint probability that a document x  contains term t  and also belongs to category ic ; ( | )iP c t : the probability that a document x belongs to category ic ?under the condition that it contains  term t.
693( | )iP t c : the probability that, a document x does not contain term t with the condition that x belongs to category ic ; Some other probabilities, such as ( )P t , ( )iP c , ( | )iP t c , ( | )iP t c , ( | )iP c t ,  and ( | )iP c t , are similarly defined. 
1{ }mi ic = : the set of categories; iA : the number of the documents that contain the term t  and also belong to category ic ; iB : the number of the documents that contain the term t  but do not belong to category ic ; iN : the total number of the documents that belong to category ic ; allN : the total number of all documents from the training data. iC : the number of the documents that do not contain the term t  but belong to category ic , i.e., i iN A?  iD : the number of the documents that neither contain the term t  nor belong to category ic , i.e., all i iN N B? ? ;
 In sentiment text classification, we also use two data sets: one is the widely used Cornell movie-review dataset2 (Pang and Lee, 2004) and one dataset from product reviews of domain DVD3 (Blitzer et al., 2007)
