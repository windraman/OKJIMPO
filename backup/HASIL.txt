Using SVM as the classifier, the macro-precision, macro-recall and macro-f1 used to evaluate the performance shown by our experiment are high
Further, in part 5, the experiment we have done is described, demonstrating the effectiveness and efficiency our method can gain regarding to the final classification performance by analyzing the performance evaluation data.
2) Our method shows a good property.
 that our method can gain higher performance at a very low dimension, and quickly reach a peak, which means much less computing time and almost best performance while the other two classical methods
 The classification performance gained using the new method proposed in this paper doing feature reduction is very effective and efficient especially when compared with the one gained using the classical methods, which are reported having better performance in [11].
Our experimental results show thatTCFS with CHIR has better clustering accuracy in terms of theF-measure and the purity.
Our experimental results with various real data sets demon-strated that the TCFS algorithm using the CHIR feature selectionmethod performs better than k-means, k-means with the TermStrength (TS) feature selection method [12], the IF method, andTCFS with other supervised feature selection methods in termsof the accuracy of clustering results.
In our research, we found the feature selection method CHIdoes not fully explore all the information provided by the ?2term-category independence test
The proposed semi-supervised method obtains satisfactory subsets of features when there is not enough TABLE I.  RESULTS IN COVTYPE WITH 25, 50, 100, 500 AND 1000 SAMPLES LABELED.  5 feat supT=54.95 nsup=39.89 15 feat supT=91.73 nsup=39.91 30 feat supT=93.57 nsup=40.01 sup ssfc sup ssfc sup ssfc 25 49.76 69.54 63.87 93.47 73.07 93.47 50 48.21 69.46 60.62 93.47 78.08 93.47 100 42.22 59.75 55.47 93.47 82.67 93.47 500 47.66 70.58 93.47 93.47 93.47 93.47 1000 50.39 74.32 93.47 93.47 93.47 93.47 TABLE II.  RESULTS IN GISETTE WITH 25, 50, 100, 500 AND 1000 SAMPLES LABELED.  5 feat supT=57.83 nsup=66.94 15 feat supT=86.43 nsup=83.17 30 feat supT=91.46 nsup=89.74 sup ssfc sup ssfc sup ssfc 25 61.57 69.87 79.23 86.13 80.94 91.09 50 72.21 71.54 82.10 87.13 85.25 90.57 100 72.88 74.67 83.37 84.00 84.82 89.37 500 70.70 75.30 86.06 85.43 89.31 89.09 1000 70.65 72.34 87.35 85.92 89.60 89.18 TABLE III.  RESULTS IN 92AV3C WITH 25, 50, 100, 500 AND 1000 SAMPLES LABELED.  5 feat supT=72.35 nsup=76.90 15 feat supT=80.43 nsup=81.34 30 feat supT=82.42 nsup=76.98 sup ssfc sup ssfc sup Ssfc 25 64.25 62.08 77.12 77.48 80.53 79.34 50 67.51 69.25 76.70 78.62 79.43 80.28 100 71.72 72.38 76.84 79.44 78.14 80.39 500 72.92 72.91 79.92 81.04 81.16 81.73 1000 74.42 73.11 80.60 80.28 81.80 81.94 TABLE IV.  RESULTS IN OPTDIGITS WITH 25, 50, 100, 500 AND 1000 SAMPLES LABELED.  5 feat supT=68.14 nsup=20.32 15 feat supT=95.48 nsup=69.89 30 feat supT=98.07 nsup=90.71 sup ssfc sup ssfc sup Ssfc 25 45.94 41.67 89.25 87.85 96.75 97.06 50 49.44 46.92 90.03 91.90 97.16 97.31 100 53.52 56.39 93.56 93.70 97.96 97.88 500 64.33 62.46 95.01 93.77 98.02 98.09 1000 62.46 65.64 95.06 95.33 97.28 98.18 538        Figure 1.  Results of classification accuracy with KNN for database gisette (left) and optdigits (right). We plot for 25, 100 and 1000 numbers of samples labeled (top to bottom). 539 labelled information. In these cases, using jointly the labelled and unlabeled information improves the selected features. 
Our results show that in general, eachfeature selection technique will create diverse feature subsetswhen compared to the other members of the family
In terms of similarity, we �?nd that each ranker in theFOS family of techniques will create diverse feature subsetswhen compared to other members of the family. The onlyexception for this is Fold Change Difference and SAMwhich consistently achieve above 0.7 similarity score for155
In terms of classi�?cation, we can see that despite thediversity of the feature subsets, the classi�?cation resultsof the rankers are quite similar with one exception: FoldChange Ratio. Fold Change Ratio achieves much differentresults than the other members of the family and is foundto be the worst ranker of the set of FOS rankers in termsof classi�?cation results
As for the topperformers, we �?nd that SAM followed by Signal-to-Noiseare commonly the top performers within all three learners.
we recommend SAM and S2N for classi�?cationresults. However, the entire FOS set of feature rankers (withthe exception of Fold Change Ratio) are comparable to eachother.
This paper shows that binary relevance-based methods have much to of-fer, especially in terms of scalability to large datasets
Using a variety of multi-label datasets and evaluation measures, we carriedout empirical evaluations against a range of algorithms. Our classifier chainsmethod proved superior to related methods, and in an ensemble scenario wasable to improve on state-of-the-art methods, particularly on large datasets.
We find that exact word formsaren�t necessary for accurate classification.
We show that by using a variant of SVM �Anchored SVM Learning (Goldberg and Elhadad,2007) with a polynomial kernel, one can learnaccurate models for English NP-chunking (Mar-cus and Ramshaw, 1995), base-phrase chunking(CoNLL 2000), and Dutch Named Entity Recog-nition (CoNLL 2002), on a heavily pruned featurespace. Our models make use of only a fractionof the lexical features available in the training set(less than 1%), and yet provide highly-competitiveaccuracies.
Without fea-ture pruning, we achieve an F-score of 90.9. Thisdataset proved to be quite resilient to feature prun-ing.
Without fea-ture pruning, we achieve an F-score of 90.9.
For all the sequence labeling tasks we analyzed,the anchored-SVM proved to be robust to featurepruning.
we cannot conclude that lexical infor-mation is not needed
There is a significant differ-ence between the pruned and non-pruned modelsfor the chunking task. W
We showed that this dif-ference can be bridged to some extent by a binaryfeature relating to idiomatic word usage, and thatthe difference vanishes when testing outside of theannotated corpus. 
The results of this work suggest that grammatical features can play a role in predicting reading diffi-culty levels for both first and second language texts in English.
We foundabout 63 million facts in G?, the superset of theground truth G. File : docD2Section Title : 1 Overview2 Partially Supervised Relation Extraction5 Experimental Results6 Related Work
As we conjectured,for this relation (which lacks true integrity constraints), theEM-based methods have higher accuracy than the constraint-based method. 
For Datasets 1 and 2, the performance results show thatthe two-step approach (Experiments 2, 3, and 4) outper-forms the one-step approach (Experiment 1). 
For Dataset 3, the two-step ap-proach slightly decreased the performance; however, thedifferences are too small to draw strong conclusions. 
This means the tagset used in theone-step approach is much smaller, and thus the one-stepsegmentation model can be better trained on a comparably2005small dataset.
The results indicate thaton average, for K4, the best performing kernel, we obtainedan increase of 24.66% in the F-score when features providedby the semantic parsers were added. When relying on SDTs,the average Precision that was obtained was 89.3%, the re-call was 76.4%, thus an F-score of 82.35%, when using thesame data as [1]. 
The re-sults show that frame semantics produce an enhancement of53.24% over previous state-of-art results in relation extrac-tion. Furthermore, they show that semantic representationssuch as frames or predicate-argument structures have a widerimpact on classification performance than the classificationtechnique.
The results for different thresholds of p(r|w) areshown in Figure 3. As can be seen, the MLE base-lines (in red with syntactic patterns and green withintertext) perform consistently worse than the mod-els learned using the topic models (in pink and blue).The difference in precision, aggregated across all re-lations, is statistically significant at 95% confidencefor most of the thresholds.File : docD6Section Title : I. INTRODUCTIONII. RELATED WORKSIII. TEXT SEGMENTATION BASED ON HIERARCHICALIV. PERFORMANCE EVALUATIONSB. Experimental ResultsV. CONCLUSION AND FUTURE WORKS
The experimental results in Table II are reported when the number of segments is unknown in advance. From Table II, the proposed linear text segmentation algorithm (i.e., TSHAC) outperforms the linear time algorithm, TextTiling, and the more complex algorithms, C99. TSHAC also provides comparable results with other algorithms. Moreover, unlike TSF, which requires manpower to designate parameters used, TSHAC provides a fully automatic process for linear text segmentation without auxiliary knowledge base, parameter setting, or user involvement.  
Compared with the classical document frequency incorporated feature filtering methods analyzed in section 4, such as DF, CHI used in our experiment, it shows in Figure 1, that our method can gain higher performance at a very low dimension, and quickly reach a peak, which means much less computing time and almost best performance while the other two classical methods and the like only show a slow ascend tendency from a lower performance evaluation value without a peak until the dimension reaches to almost the original one, which means decreasing the dimension dramatically without great loss of performance is hard to realize. 
Our experimental results indicate that CHIR consistently out-performs other three methods in terms of increasing the cohe-siveness values of the clusters. The performance of CC and CHIare very close in some cases, which tells us that identifyingonly the positive term-category dependency is not suf?cient.The term-goodness measure should also describe the dependencyaccurately. SCHI does not perform well in most cases becausethe de?nition of s?2 (see Equation 9) does not contain suf?cientinformation about the ?2 term-category independence test.
 In these cases, the unsupervised information improves the accuracy and the ssfc method is adequate (see gisette in figure 1). Optdigits is a database where sup technique gets high-quality features for few labeled samples. Thus, in this case the ssfc has similar performance than sup. Nevertheless when the number of labeled samples is increased, ssfc and sup become similar to supT. 
 Finally, this paper suggests that applying two or more technique i.e. hybrid approach gives better solution for class imbalance problem. 
The experimental results on data sets from both topic-based and sentiment classification tasks show that this new method is robust across different tasks and numbers of selected features. 
we can see that the MI score is based on the second basic measurement. This method assumes that the term with higher category ratio is more effective for classification
we can say that the IG score is influenced by the two basic measurements. 
we see that the CHI score is related to both the frequency measurement iA
 and ratio measurement /i iA B
 we can easily draw the two following conclusions: 1) Given the same value of iA , the BNS score increases with the increase of i iA B? . 2) Given the same value of i iA B? , BNS score increase with the decrease of iA . 
In summary, the BNS FS method is biased towards the terms with the high category ratio but cannot be said to be sensitive to document frequency. 
Good categorization performance was achieved using a statistical classifier and a proportional assignment strat- egy.
 We have also shown, via studying text cate- gorization effectiveness, a variety of properties of index- ing languages that are difficult or impossible to measure directly in text retrieval experiments, uch as effects of feature set size and performance of phrasal representa- tions in isolation from word-based representations. 
The results we obtained using only 3% of the availablefeatures are among the best reported, including results ob-tained with the full feature set.
We have proposed a framework for evaluating summariza-tion methods in the context of their utility as feature selec-tors in automatic text categorization. 
 Our approach is wellsuited for classifiers utilizing binary feature vectors, where afeature corresponds to the presence or absence of a word ina document.
RESULTS: The pro-posed method outperformed the previousapproaches, achieving 95.5% per-sentenceaccuracy and 68.8% per-abstract accuracy.CONCLUSION: The experimental resultsshowed that CRFs could model the rhetor-ical structure of abstracts more suitably.
The CRF clas-sifier had roughly 5% advantage on per-abstract ac-curacy over SVM. 
In this section we present our algorithm for assigning oneof 15 section types. 
We hypothesize that section sequences can improve theaccuracy of section label classi?cation.
Finally, we have assumed that text span boundaries inclinical notes are known, which is unusual in practice. Inorder to improve the accuracy of the classi?er, a future di-rection for this study is to segment and classify text spansat the same time.
This paper proposes a new approach to segment and classify the document regions as text, image, graphics and table.
Multilayer perceptron, a supervised learning technique has been used to construct the classifier and found 97.49% classification accuracy. 
From the above comparative analysis it is observed that classification accuracy produced by multilayer perceptron is higher than na�ve bayes and J48.
This paper demonstrates the modeling of document segmentation as classification task and describes the implementation of machine learning approach for segmenting the document into various regions.
Again, the results are good.
Examining the trees learned we can conclude that most ofthe possible semantic classes are not covered.
We have proposed a system for the detection of marked andexplicit causations between a verb phrase and a subordi-nate clause which yields a high performance.
The systemis relatively simple and is able to detect causations fromopen domain text.File : docH10Section Title : 1 Introduction2 The Method3 Empirical Results4 Summary
While our method outperforms the subtree kernels bothin precision and recall, the shortest path kernel only in precision.
Though theshortest path kernel has better recall, we note that our method is more generalthan the shortest path kernel, as it is not restricted to binary target relations.
Empirical results on a popularbenchmark dataset indicate that the performance of our method is comparablewith state-of-the-art methods.
First we observe that the maximal clique methodcombined with maximum entropy (system MC) re-duces the relative error rate over naively enumer-ating and classifying all instances (system NE) by21%.
The system basedon binary factorization not only is more efficientthen naively enumerating all instances, but signifi-cantly outperforms it as well.
We showed that such a method can be suc-cessful with an empirical evaluation on a large setof biomedical data annotated with genomic varia-tion relations.
In fact, this approach is both signifi-cantly quicker and more accurate then enumeratingand classifying all possible instances.
Indeed, asshown in Table 1, precision value is 0.806 in case that the number of seed pairsis 10, and it is within a range of 0.2 to 0.4 in other cases.
On the other hand, anumber of false negative pairs resulted in low recall.
Ourmodel is able to extract 10,000 instances of 102 re-lations at a precision of 67.6%.
We also analyzefeature performance, showing that syntactic parsefeatures are particularly helpful for relations that areambiguous or lexically distant in their expression.
At most recall levels, the combination of syn-tactic and lexical features offers a substantial im-provement in precision over either of these featuresets on its own.
At a recall of 100 instances, the combination oflexical and syntactic features has the best perfor-mance for a majority of the relations, while at a re-call level of 1000 instances the results are mixed.
Our results show that the distant supervision algo-rithm is able to extract high-precision patterns fora reasonably large number of relations.
Our results thus suggest that syntactic featuresare indeed useful in distantly supervised informa-tion extraction, and that the benefit of syntax oc-curs in cases where the individual patterns are par-ticularly ambiguous, and where they are nearby inthe dependency structure but distant in terms ofwords.
The results obtained on the ACE Relation Mention Detectiontask outperform in terms of F1 score by 5 points the state of theart of unsupervised techniques for this evaluation framework,in addition to being simpler and more flexible.
 Our approach obtains a F1 measureof 55.7, more than 4 points above the upper bound of51.0 attainable by the other system, with both using onlyPOS information.
Additionally, we have shown that learning using a massivecombination of clusterings improves the performance ofthe scorer, with respect to a learner based on a singleclustering model and a model selection criterion.
The results demonstratea clear superiority of a diversity based approach to a non-diversity based approach.
At compression rates between 20% and 40%, despitesome outliers, DBS/XM performs better for the majorityof queries than Z-model, but breaks even at 50%.
On the other hand, under MRS,DBS/XM turned out to be signi?cantly di?erent from Z-model at every compression rate examined.
DBS/XM performs consistently betterthan Z-model under MRS.
Under this scheme,diversity-based summarization (DBS/XM ) was found to besuperior to relevance-based summarization (Z-model).
Using a few simple rules applicableto the output of a deep parser called Mogura,we showed that sentence simplification is effec-tive for relation extraction.
Applying all the rulesimproved the performance on three of the fivecorpora, while applying only the clause-selectionrules raised the performance for the remaining twocorpora as well.
We analyzed the simplificationresults, and showed that the simple rules are ap-plicable with little danger of changing the truth-values of the interactions.
TheEmbra system performance is better than mean and me-dian system scores for the responsiveness measure andfor three of the five linguistic quality measures (grammat-icality, non-redundancy and focus).
It is just below meanand median scores for structure/coherence.
We observed an insignificant but positiveimprovement in the Rouge-2 recall of 0.8% while Rouge-SU4 recall exhibited a slight decrease of 0.2%.
For bothofficial DUC 2005 measures, the precision increased giv-ing slightly higher combined F-scores. For Rouge-2, pre-cision improved by 1.2%. And for Rouge-SU4, precisionimproved by 0.2%.
The results show there is a trade-off amongthese factors for relation extraction and the features containing moreinformation such as semantic ones can improve the performance of theontological relation extraction task.
The results show that performance on relation detection level is the highestwhile that on subtype classification is the lowest.
The performance for the type EMP-ORGwhen classifying on the type level is the best among all 7 relation types: 77.29%Precision, 75.00% Recall and 76.01% F1 averaged over 5 folds cross validation.
However, the performance on the 7 subtypes within EMP-ORG when classifyingat subtype level is not only much lower than the result for EMP-ORG overallbut also rather unstable: from zero for Partner to 72.79% for Subsidiary.
Thetwo biggest subtypes Employ-Exec and Employ-Staff get only 67.16% and 62.25% F1 which are much lower than the 76.01% on type level for their parent typeEMP-ORG.
But the improvement atvarious levels is different: as more features are used, the improvement in relationdetection is only 10.34% (from 61.25% to 71.59%), while the improvement intype and subtype classification is much more significant: 23.59% (from 41.61%to 65.20%) and 23.40% (from 33.38% to 56.78%).
For the in-domain setting, our joint modelleads to 4% higher precision than an isolatedlocal approach, but has no advantage over apipeline.
For the out-of-domain data, we ben-efit strongly from joint modelling, and observeimprovements in precision of 13% over thepipeline, and 15% over the isolated baseline.
For example, the held-out experiments with 200,000NYT documents finish within three hours.
When applied to out-of-domain text, this approachleads to a 15% increase in precision over an isolatedbaseline, and a 13% improvement over a pipelinedsystem.File : docH2Section Title : 1 Introduction2 Shallow Semantic Parsing5 Experimental results6 Conclusions
The results indicate thaton average, for K4, the best performing kernel, we obtainedan increase of 24.66% in the F-score when features providedby the semantic parsers were added.
The re-sults show that frame semantics produce an enhancement of53.24% over previous state-of-art results in relation extrac-tion.
This structure enabled the extraction of rele-vant relations with better performance than previous state-of-the-art kernel methods.
Furthermore, the semantic featuresenabled similarly good results to be obtained with a few otherlearning algorithms.
In the first case when the feature number is low (about less than 1,000), the FS methods in the second group including IG, CHI, WLLR,  always perform better than those in the other two groups.
In the second case when the feature number is large, among the six traditional methods, MI and BNS take the leads in the domains of 20NG and Movie while IG and CHI seem to be better and more stable than others in the domain of DVD.
As for WFO, its performances are excellent cross all these three domains and different feature numbers.
The experimental results show that our framework helps us to better understand and compare different FS methods.
Furthermore, the novel method WFO generated from the framework, can perform robustly across different domains and feature numbers. 
To prove this, we conducted a Na�ve Bayesian classification experiment on Web Directory dataset and found that the classification accuracy increased from 49.6% to 57.6% after removing 98% terms.
Finally, compared with other unsupervised feature selection methods, TC is better than DF and En, but little worse than TS.
About 8.5% entropy reduction and 8.1% precision improvement are achieved while 96% features are removed with TS method.
For example, after 11 iterations with CHI selection on Web Directory dataset (nearly 98% terms removal), the entropy was reduced from 2.305 to 1.994 (13.5% entropy reduction relatively) and the precision was improved from 52.9% to 60.6% (14.6% precision improvement relatively).
It is found that its performance is close to the ideal case and much better than any unsupervised methods.
The results show that for both the first and sec-ond language corpora, the language modeling (LM) approach alone produced more accurate pre-dictions than the grammar-based approach alone.
The results also indicate that while grammar-based predictions are not as accurate as the vo-cabulary-based scores, they can be combined with vocabulary-based scores to produce more accurate interpolated scores.
When interpolated with grammar-based scores, the reduction of mean squared error over the language modeling approach for L1 was only 7%, while for L2 the reduction or squared error was 22%.
Although a vocabulary-based language modeling approach outperformed the grammar-based predictor, an interpolated measure using confidence scores for the grammar-based predic-tions showed improvement over both individual measures.
Also, grammar appears to play a more important role in second language readability than in first language readability.
Results show that our summarizing abstractfeature extraction method encouragingly enhances classi?cation performances on most of the classi?ers whencompared with other methods.
 Comparisonand test results show that the AFE scores the highest F1 measure on the Reuters dataset with 96.9%, the 20Newsgroups dataset with 94.8%, and the ModApte-10 with 96.1%.
This means that the AFE achieves a betterF1 measure of 3.7% on the Reuters, 19.4% on the 20 Newsgroups, and 3.4% on the ModApte-10 than its nearestfollowing non-AFE method.
Looking at the average F1 measures of the classi?ers, we see that the AFE�s scoreis 9.2% higher on Reuters, 33.0% higher on 20 Newsgroups, and 7.3% higher on ModApte-10 than the next bestscored method.
The optimal feature set size for word-based indexing was found to be surprisingly low (10 to 15 features) despite the large training sets.
Syntactic indexing phrases, clus- ters of these phrases, and clusters of words were all found to provide less effective representations than individual words.
Disappointingly, as shown in Figure 5, term cluster- ing did not significantly improve the quality of either a word-based or phrasal representation.
We have shown a statistical classifier trained on manu- ally categorized documents to achieve quite effective per- formance in assigning multiple, overlapping categories to documents.
We have also shown, via studying text cate- gorization effectiveness, a variety of properties of index- ing languages that are difficult or impossible to measure directly in text retrieval experiments, uch as effects of feature set size and performance of phrasal representa- tions in isolation from word-based representations.
We report average precision of0.85 and recall of 0.59 when segmenting unseen test meetings.
Er-ror analysis of our results shows that although the basic idea of ouralgorithm is sound, it breaks down when participants stray fromtypical behavior (such as when they monopolize the conversationfor too long).
On performing this experiment across all the 6 data combi-nations, we get an average precision of 0.85, recall of 0.59 andf�measure of 0.67 on unseen test data.
The exact �best�window size for the two predictors changes based on the trainingdata; the average being 56 seconds for the speech activity predic-tor and 70 seconds for the all words predictor.
The average bestweight for linear combination is 0.6 for the speech activity bound-ary predictor (and 0.4 for the all words predictor).
Our empirical evaluation showsthat the strategy with provable performance guarantees per-forms well in comparison with other commonly-used featureselection strategies.
In addition, it performs better on cer-tain datasets under very aggressive feature selection.
All the selection strategies except document frequency (DF)and uniform sampling (US) achieve 85% of the original (in-volving no sampling) micro-averaged F1 performance withonly 500 out of the (roughly) 20K original features.
In gen-eral, the subspace sampling (SS) and information gain (IG)strategies perform best, followed closely by weighted sam-pling (WS).
In general, SSwith k = 1500 strategy outperforms the other unsupervisedfeature selection strategies; however, it is only marginallybetter than the WS and DF methods.
As with 20-Newsgroups, the IG-based feature selection strategy performs marginally betterthan the others.
In fact, for this dataset, the DF selectionstrategy also slightly outperforms the subspace-based meth-ods.
From the extracted relations, the system built 306 clus-ters of two or more instances, which were manuallyevaluated by two authors of this paper.
81 of our clus-ters contain two or more instances of exactly the samerelation, mostly due to the same sentence appearingin several documents of the corpus.
Of the remaining225 clusters, 121 were marked as consistent (i.e., all in-stances in the cluster express a similar relation), 35 aspartly consistent (i.e., more than half of the instancesin the cluster express a similar relation), 69 as not use-ful.
Of our 121 consistent clusters, 76 were classified as be-ing of the type �same pattern�, 27 as being of the type�same topic� and 18 as being of the type �relation para-phrases�.
For the same sentences, the IDEX system extracted 27relations, 11 of them corresponding to the manuallyextracted ones.
This yields a recall value of 73% anda precision value of 41%.
Contrastive error analy-sis (with and without lexical features) in-dicates that lexical features do contributeto resolving some semantic and complexsyntactic ambiguities � but we find thiscontribution does not generalize outsidethe training corpus.
We find that exact word formsaren�t necessary for accurate classification.
For all the sequence labeling tasks we analyzed,the anchored-SVM proved to be robust to featurepruning.
The experiments support the claim thatrare lexical features do not provide substantial in-formation to the model, but instead play a role inmaintaining separability.
When this role is takenover by anchoring, we can obtain the same levelof performance with very few robust lexical fea-tures.
Counting clearly distinct propositions in both cases, yields a 60% greater information content for the MMR- MD case, though both summaries are equivalent in length.
When these 200 documents were added to a set of 4 other topics of 200 documents, yielding a document-set with 1000 documents, the query relevant multi-document summarization system produced exactly the same re- suits.
Evaluation results show that the proposed approach performs comparable to the state of the art, while exhibiting a bias towards precision, which is a sign of conservative generalisation.
Evaluation results suggest that the proposed approach performs well in comparison to the state of the art, despite the difficulties of comparing results obtained on different corpora.
In addition, the fact that the proposed approach does not involve any abstraction other than the generalisation performed by the grammatical inference algorithm, allowed us to get an estimate of the degree of generalisation that can be achieved by the algorithm. This was measured to be at least 10 pp accompanied with a degradation in precision of about 29 pp.
Feature selection methods can improve the performance oftext clustering as more irrelevant or redundant terms areremoved.
TCFS with a supervised feature selection method, such asCHIR, CHI or CC, can achieve a better F-measure than k-means with TS.
k-means with TS does not consistently outperform k-meansas the percentage of feature selection is varied.
The purity valuesof the clustering results obtained by performing k-meanswith TS on the EXC data set are consistently lower thanthose of performing k-means.
TCFS with CHIR outperforms all other clustering algorithmsin terms of the F-measure and the purity value for differenttest data sets.
The experimental results suggest that the performance of TCFSis better than that of IF (with one iteration of k-means) in mostcases.
We show that using the mode topic ID as-signed during the inference method of LDA,used to annotate unseen documents, improvesperformance by stabilizing the obtained top-ics.
We show significant improvements overstate of the art segmentation algorithms on twostandard datasets.
As an additional benefit,TopicTiling performs the segmentation in lin-ear time and thus is computationally less ex-pensive than other LDA-based segmentationmethods.
Using a one-sampled t-test with ? = 0.05 we can state significant improve-ments in comparison to all other algorithms.
Consideringthe unfiltered results we observe that results improvewhen using the mode assigned topic ID and a win-dow of larger than one sentence.
Fil-tering the documents for parts of speech leads to ?1% absolute error rate reduction, as can be seen inthe last two columns of Table 4.
Again, we observethat the mode assignment always leads to better re-sults, gaining at least 0.6%.
The tiles have been found to correspondwell to humanjudgements of themajor subtopicboundaries of sciencemagazine articles.
The structure it obtains is coarse-grained but generallyreflects human judgement data.
In all but two cases (using Logistic Regression andeither 75 or 200 features), FCR is the worst performerby a clear margin.
This leads us tostate that the set of FOS techniques, while diverse in theirselections for the feature subsets, will perform similarly toeach other in terms of classi?cation (with the exception ofFCR).
In terms of similarity, we ?nd that each ranker in theFOS family of techniques will create diverse feature subsetswhen compared to other members of the family.
If one ignores Fold Change ratio,then the difference between the best ranker and the worsthas a maximum of 0.03080 in terms of AUC.
As for the topperformers, we ?nd that SAM followed by Signal-to-Noiseare commonly the top performers within all three learners.
Note that the supervised method that uses all labelled samples (supT) always obtain better accuracy than the unsupervised method with all the samples (nsup), except in 92AV3C where both methods have similar performance.
Notice also that, in general, jointly supervised and unsupervised information improve the results, particularly when the unsupervised version tend to perform poorly, and adding few labeled sample increase the accuracy in a significant way.
Thus, the proposed hybrid method (ssfc) and its supervised version (sup) are better when the number of labeled samples is increased.
When the number of labeled samples is sufficiently large, the performance of ssfc and sup converge.
The percentage of the extracted text was 99-100% of alltext in test images.
The best precision score was 0.77 when run on the New York Times texts, and it wasaccompanied by a recall score of 0.77 as well.
While these scores may sound relatively impressive, it is important tonote that they were only numerically evaluated on this one set of data, and so it is unlikely that those parameterswould return such high scores in all circumstances.
While this system fails to perform as well as manyof the other segmentation systems that have recently been presented in the literature, it is certainly on the right pathand can produce good results with the proper parameters.
The results show thatdegree-based methods (including LexRank) outperform both centroid-based methods andother systems participating in DUC in most of the cases.
Furthermore, the LexRankwith threshold method outperforms the other degree-based techniques including continuousLexRank.
All of ourthree new methods (Degree, LexRank with threshold, and continuous LexRank) performsignificantly better than the baselines in all data sets.
They also perform better thancentroid-based summaries except for the DUC 2003 data set where the difference betweenCentroid and the others is not obvious.
Lastly, we haveshown that our methods are quite insensitive to noisy data that often occurs as a result ofimperfect topical document clustering algorithms.
It keeps the best features, and thus improves the final performance e.g. macro-f1 to 0.92 and simultaneously decreases the computing time for representing the incoming text waiting to be classified dramatically, which is important because it occurs on line and is time-critical.
Feature reduction is really important because without it, the performance value is only 0.73 of macro-f1, much lower than the one gained with reduced feature space� size.
Our method shows a good property. The performance evaluation data are still high when the dimension is reduced to 100, and it gradually inclines to reach a peak with macro-f1 value of 0.9186 when the dimension is 400.
Compared with the classical document frequency incorporated feature filtering methods analyzed in section 4, such as DF, CHI used in our experiment, it shows in Figure 1, that our method can gain higher performance at a very low dimension, and quickly reach a peak, which means much less computing time and almost best performance while the other two classical methods and the like only show a slow ascend tendency from a lower performance evaluation value without a peak until the dimension reaches to almost the original one, which means decreasing the dimension dramatically without great loss of performance is hard to realize.
The first hypothesis was only marginally confirmed in the experiment (0.05 < p < 0.10), whilethe second one was confirmed at p < 0.05.
Argu-ments generated for the TC condition had greater satisfaction z-scores than arguments generated for the TV, NTC andNA conditions.
The difference in effectiveness between arguments generated in the TC condition and arguments gen-erated in the TV condition was statistically significant (p < 0.05), while the difference in the other two comparisonsTC vs. NTC and NA was only marginally significant (p < 0.1).
While the second hypothesis was confirmed in the experiment, the first one was only marginally con-firmed.File : docH4Section Title : 1 INTRODUCTION2 METHODS4 RESULTS AND DISCUSSION5 CONCLUSIONS
We applied RelEx on a comprehensive set of one millionMEDLINE abstracts dealing with gene and protein relations andextracted ~150000 relations with an estimated perfomance of both80% precision and 80% recall.
Evalua-tion results obtained on the LLL-challenge dataset (Figure 4,F 75%, R 83%, P 68% on the training set; F 72%, R 78%,P 68% for the basic test set) show that RelEx returns relationswith significantly higher recall and precision than the approachespreviously applied for the LLL-challenge [F 51.8%, R 53.8%,P 50.0% for the basic and F 54.3%, R 53.0%, P 55.6% for thelinguistically enriched test set (Ne�dellec, 2005)].
For both datasets (LLL and hprd50) RelExachieves significantly higher precision and thus F-measure thanco-occurrence-search.
RelEx extracts a significantly largernumber of relations from the abstracts than the number of interac-tions contained in HPRD.
If RelEx is compared on the rather stringent criteria of the LLLchallenge dataset (Ne�dellec, 2005), performance is significantlyhigher than previously reported results.
As can be seen, an improvementby using an evaluation corpus was obtained employing the TP technique witha neighbourhood of 40%, which is exactly the same percentage used in otherresearch works (see [10] and [13]).
We may observe that by using the same information from a web page, wehave slightly outperformed the results obtained by other approaches, even whenwe have trained our model with only 3 target web pages in average per query,and executing 100 iterations on the Expectation-Maximization model.
As can be seen in Table 1, the individual CLIR models perform similar tothe results reported in previous works: the Wikipedia model achieves 50-80%of the monolingual result, while Google Translate performs around 90% of themonolingual run.
The Wikipedia based concept mapping performs slightly worsethan the more complex WP model by [5] but we use just title fields.
As regards the combination of the Wikipedia based and the Google trans-lations, we see consistent improvements over the CLIR models using a singletranslation.
This simpleWP-based model performs similar to previous results obtained by Wikipedia-based CLIR (60-70% accuracy of monolingual retrieval).
Retrieval performance with queries generated utilizing Mecab was very low.
Our preliminary experiments showed the superiority of the longest much technique applying SPACEALC over Mecab: Segmentation of Japanese texts is much more accurate.
Results of preliminary experiments showed that queries generated are similar to queries obtained from Google Translate service.
The performance of the retrieval system for queries generated by the proposed approach is slightly worse compared to the performance for the queries obtained from Google Translate service.
The system achieved a performance of 67% compared to the monolingual baseline.
Averaging the runs with these settings over the years 2004, 2005 and 2006 shows us that Spanish had an average perform-ance of 71.89% and French had an average of 76.78%.
Including translations only as a phrase query results in a average MAP decrease of 0.0990.
Including redirects showed an average MAP decrease of 0.118.
Filtering non-related words lead to an MAP increase of 0.0926.
In the experiments, our methodachieved 97% of manual translation case in terms of the average precision.
In terms of average precisions compared with NODIS, theproposed disambiguation method improved 1.0 point forNTCIR and 0.8 point for NEAR, but decreased 0.7 pointfor AND.
In this experiment, differences of the average precisionsamong four measures were lower than 0.1% and nosignificant difference was observed.
As we can see, both NB-EM and VS-EM-Spyperform on par with the Constraint method on this task.
As we conjectured,for this relation (which lacks true integrity constraints), theEM-based methods have higher accuracy than the constraint-based method.
As we can see in Figure 7,Snowball variations with no specific tuning for DiseaseOut-breaks produce results that are comparable with those forProteus.
In fact, Snowball manages to achieve recall that issubstantially higher than that of Proteus while maintainingcompetitive precision.
We showed that ourgeneral EM-based confidence estimation method improvesextraction accuracy over heuristic-based methods, allowinga partially supervised relation extraction system to achieveaccuracy comparable to a sophisticated manually tuned state-of-the-art information extraction system.
The experimental result shows that our proposed method brings significant improvement in retrieval accuracy for English document collections, but deficient for Malay document collections.
As shown in Table 4, the English document MAP results for IR2 were 2.1 and 5.1% lower than mono IR1 result and the Malay document MAP results for IR2 were 3.4 and 7.5% lower than mono IR1 result, as expected.
The English document MAP result for IR3 is higher than IR2 by 2 and 0.6% and the Malay document MAP result for IR3 is lower than IR2 by 2.5 and 2.8%, respectively.
As can be seen in this figure, dictionary-based CLIR approach in IR2, showed decreasing in retrieval performance compared to Mono IR system in IR1.
As shown in Table 4, the MAP results for using first translation were 3% and 4.1% higher than using all translation candidates result for English and Malay document collections.
Translation approach in IR2 and IR3, showed that CLIR query translation using first translation listed in the dictionary is obtained a better result compared to using all translation candidates listed in the dictionary either in English or Malay document collections.
We find that hybrids of document and query translation-based systems out- perform query translation systems, even human-quality query translation systems.
We ob- serve that the hybrid systems which combine query translation and document translation outperform both query translation and doc- ument translation individually, on both sets of documents.
Surprisingly, we find that the hybrid system outperforms the pure monolingual system.
We find no clear advantage for either the query trans- lation system or the document translation system; instead French=eeEnglish translation appears advantageous over English~French translation, in spite of identical procedures used in constructing both.
However a hy- brid system incorporating both directions of translation outperforms either.
Further- more, by incorporating human query trans- lations rather than machine translations, we show that the hybrid system contin- ues to outperform query translation.
In summary, the improvement by using NP translation for shortqueries is statistically significant (p-value = 0.015).
The additionof translation selection is also statistically significant for longqueries (p-value = 0.05).
The improvement obtained with thecombination of both approaches (i.e. NP translation andtranslation selection) are statistically significant for both shortqueries (p-value = 0.03) and long queries (p-value = 0.001).
Thecomparison with the MT approach shows that at least for shortqueries, the improvement brought by our methods is statisticallysignificant (p-value = 0.02).
The combination of our approach with the MTsystem leads to a high effectiveness of 105% of that ofmonolingual IR.
Evaluated based on user feedback collected through AmazonMechanical Turk, our experimental results show that theBoolean filtering approach, which is widely used in facetedsearch in e-commerce, doesn�t work well for text documentretrieval, due to the incompleteness (low recall) of metadataassignment in semi-structured text documents.
The average MAP and P@10 of using faceted feed-back on OHSUMED dataset are improved by 32.4% and43.9% over the baseline (BM25) respectively.
The averageMAP and P@10 on RCV1 dataset are improved by 11.1%and 8.8% respectively.
The Boolean A+O worksbetter than Boolean AND while still worse than BooleanOR.
Table 6 shows that FF per-forms better than PRF, and closely to RRF on OHSUMEDdataset; FF performs worse than PRF and RRF on RCV1dataset, and 10% better than BM25.
The proposed soft modelis shown consistently more effective on both datasets, as itautomatically learns a weight for each facet, which capturesthe facet quality.
As the corresponding figures show, the LDA-only model seems to be toocoarse to be used as the only component of an IR model (e.g., due to its limited numberof topics, words in queries unobserved during training).
However, the combination ofthe LDA-only and the simple unigram model, which allows retrieving relevant docu-ments based on shared words across the languages (e.g. personal names), leads to muchbetter scores which are competitive even with models which utilize cross-lingual dic-tionaries or machine translation systems.
For instance, our LDA-unigram model wouldhave been placed among the top 5 retrieval systems for the CLEF 2002 Bilingual toDutch task, would have been placed among the top 3 retrieval systems for the CLEF2001 Bilingual to Dutch task, and outperforms the only participating system in theCLEF 2002 Dutch to English task (MAP: 0.1495) [20, 21].
We have thoroughly evaluated this cross-language retrieval model using standardtest collections from the CLEF 2001-2003 CLIR campaigns and have shown that ourcombined model, which fuses evidence from the BiLDA model and the unigram model,is competitive with the current top CLIR systems that use translation resources that arehand-built or are trained on parallel corpora.
As shown in Table 1, the hybrid approach using English documents translated from the original collection (hybrid-2, SrgMgE03) outperforms another hybrid approach using German documents (hybrid-1, SrgdMgG02), i.e., the scores of mean average precision (MAP) are 0.2605 for hybrid-2 and 0.2492 for hybrid-1.
Unfortunately, the hyper approach could not show better performance than a simple query translation approach (SrgdQT04), i.e., its score of MAP is 0.2658, which is slightly greater than that of SrgdMgE03.
Unfortunately, our hybrid approach could not show better effectiveness than a simple query translation approach partly because the performance of document translation is poor.
Experiments on retrieval of Arabic, Chinese, and French documentsusing English queries show that no one technique is optimal for all queries, but that statisticallysignificant improvements in mean average precision over strong baselines can be achieved bycombining translation evidence from all three techniques.
The best results are achieved when weperform a linear interpolation of all three approaches (query-based, phrase-based, and token-based).
Based on the randomized significance test proposed by Smucker et al. (2007), the combinedapproach (E) outperforms all models (except for the phrase-based approach) in the Arabiccollection with 95% confidence.
When we ran the same test on the other two collections, wefound that the combined approach is significantly better than the baseline (A) and 1-best (D)approaches for Chinese, whereas MAP is significantly higher than baseline A for French.
For French, the best retrieval effectiveness results from the n-bestfull query translation model (C), significantly better than the baseline model (A).
This showsthat there is no individual model that outperforms the rest in all three collections.
All four Tablesshow good results; a total of 1559 out of 1600 (97.4%)queries retrieved their counterpart patents at the firstrank.
A total of735 out of 800 (91.9%) queries retrieved their counter-part patents at the first rank.
A total of 334 out of 400 (83.5 %) counter-part English patent abstracts were correctly retrieved atthe first rank and 361 out of 400 (90.3 %) were re-trieved in the top 3 by the Japanese sentences.
A total of 310 out of 400(77.5 %) counterpart Japanese patent abstracts werecorrectly retrieved at the first rank and 360 out of 400(90.0 %) were retrieved in the top 3 by the Englishsentences.
The CLIRsystem produced with the method showed 97.4% accu-racy in our preliminary tests of finding the counter-parts in a parallel corpus of English and Japanese pat-ents.
More than half of the queries of the complete OPF corpus, including words with spelling mistakes, URLs, etc. are expanded into several choices.
It is worth noticing that the quantity of words provided by QE is unevenly spread across different queries.
Silence reduction, which is the first aim of the proposed method, is significant as the results in IV.B show.
Indeed, the expansions shown in section IV.B.1 do maintain the meaning of the original query.
Our method works quite well on the output ofsearch engines as it is shown by table below.
All the built wrappers correctlyextract the full page with a couple of instances as can be seen the ta-ble below.
In the worst case, whenall the examples need to be given, the wrapper generated can stillwork on other generated pages.
The proposed method can wrap up manydifferent types of site, is robust to irregularities in format and makesuse of structure contained in content text.
The results demonstrate unambigu-ously that the event and relation representationsoutperform the tf*idf representation, with stronglysignificant p-values less than 0.001 for both Rougemeasures and all summary lengths.
Results suggest thatthe entity pair model based on GRE data out-performs the entity pair model based on atomicevents, at least for medium sized summaries of100 and 200 words where ER is significantly betterthan EE for both Rouge measures.
The scores for the entitypair representations reported in Table 3 are statisti-cally indistinguishable from those for correspond-ing relation and event representations in Table 2above.
Performance for the re-lation representation is significantly better than anon-trivial tf*idf baseline across the range of sum-mary lengths explored.
Performance is also atleast as good as a comparable but less general rep-resentation based on event extraction.
Correlationanalysis suggests that different representations arecomplementary due to the fact that they performwell on different document sets.
We examine the utility of dif-ferent features such as Wordnet hyper-nyms, parts of speech, and entity types,and find that the dependency tree kernelachieves a 20% F1 improvement over a�bag-of-words� kernel.
The first result of interest is that the sparse treekernel does not perform as well as the con-tiguous tree kernel.
The second result of interest is that all treekernels outperform the bag-of-words kernel,most noticeably in recall performance, implyingthat the structural information the tree kernel pro-vides is extremely useful for relation extraction.
We have shown that using a dependency tree ker-nel for relation extraction provides a vast improve-ment over a bag-of-words kernel.
While the de-pendency tree kernel appears to perform well atthe task of classifying relations, recall is still rela-tively low.
The empirical investigation pre-sented here shows that accurate results, comparable to theexpert teams, can be achieved, and parametrization allowsto fine tune the system behavior for fitting the specific do-main requirements.
Although the precision score of Decision Treeand NaiveBayes are better than the model trained over thebag-of-words (i.e. a simple model), it achieves an overalllower F1 measure (0.31 and 0.4 vs. 0.45) this is due to thehigher generalisation power of the kernel methods, in factthe simple Bow model is already able to achieve an higherrecall level.
On some more complex relationshipclasses, as PP knows PP and PP hangs out at a Pl, theKXBOW kernel achieves lower performances, basically dueto the presence of dialectal or syntactically odd expressions.
As apparent, the plot shows a regular shape and itsuggests that parameter tuning can be effectively applied tocapture the required trade-off between the suitable coverageand the required accuracy of the method.
The technology designed and tested in the project has beenshown to be very effective.














































































